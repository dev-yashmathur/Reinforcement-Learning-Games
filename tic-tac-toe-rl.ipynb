{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 3\n",
    "COLS = 3\n",
    "DECAY = 0.9\n",
    "LR = 0.2\n",
    "EPSILON = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# board = np.zeros(ROWS*COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, name):\n",
    "        self.symbol = name\n",
    "        self.stateHistory = [] #Positions of the board at each step of it's play\n",
    "        self.stateValueTable = {} #Serves as the policy after training\n",
    "    \n",
    "    def addToHistory(self, state):\n",
    "        self.stateHistory.append(str(state))\n",
    "\n",
    "    def chooseAction(self, board):\n",
    "        possible = [idx for idx in range(len(board)) if board[idx] == 0]\n",
    "        if np.random.uniform(0, 1) <= EPSILON: #Condition for exploration\n",
    "            action = random.choice(possible)\n",
    "        else: #Condition for exploitation\n",
    "            bestVal = -500000\n",
    "            for move in possible:\n",
    "                possibleBoard = board.copy()\n",
    "                possibleBoard[move] = self.symbol\n",
    "                val = self.stateValueTable.get(str(possibleBoard))\n",
    "                if val is None:\n",
    "                    val = 0\n",
    "                if val > bestVal:\n",
    "                    bestVal = val\n",
    "                    action = move\n",
    "        return action\n",
    "    \n",
    "    def chooseBest(self, board):\n",
    "        possible = [idx for idx in range(len(board)) if board[idx] == 0]\n",
    "        bestVal = -500000\n",
    "        for move in possible:\n",
    "            possibleBoard = board.copy()\n",
    "            possibleBoard[move] = self.symbol\n",
    "            val = self.stateValueTable.get(str(possibleBoard))\n",
    "            if val is None:\n",
    "                val = 0\n",
    "            if val > bestVal:\n",
    "                bestVal = val\n",
    "                action = move\n",
    "        return action\n",
    "    \n",
    "    def updateStateValue(self, reward): #Backprop REWARD\n",
    "        for state in reversed(self.stateHistory):\n",
    "            if self.stateValueTable.get(str(state)) is None:\n",
    "                self.stateValueTable[str(state)] = 0\n",
    "            self.stateValueTable[str(state)] += LR*(DECAY*reward - self.stateValueTable[str(state)])\n",
    "            reward = self.stateValueTable[str(state)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.stateHistory = []\n",
    "\n",
    "    def loadPolicy(self, policy):\n",
    "        with open(str(policy), 'rb') as f:\n",
    "            self.stateValueTable = pickle.load(f) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class env():\n",
    "    board = [0 for _ in range(ROWS*COLS)]\n",
    "\n",
    "    def updateBoard(self, action, symbol):\n",
    "        self.board[action] = symbol\n",
    "\n",
    "    def checkWin(self):\n",
    "        winner = \"NA\"\n",
    "\n",
    "        draw = True\n",
    "        for i in self.board:\n",
    "            if i == 0:\n",
    "                draw = False\n",
    "\n",
    "        if draw:\n",
    "            return \"DRAW\"\n",
    "\n",
    "        #Win By Vertical 3\n",
    "        for i in range(0, COLS):\n",
    "            for j in range(0, ROWS-2):\n",
    "                if self.board[(j*COLS) + i] == self.board[(j+1)*COLS + i] == self.board[(j+2)*COLS + i]:\n",
    "                    if self.board[(j*COLS) + i] != 0:\n",
    "                        winner = self.board[(j*COLS) + i]\n",
    "        \n",
    "        #Win by Horizontal 3\n",
    "        for i in range(0, ROWS):\n",
    "            for j in range(0, COLS-2):\n",
    "                if self.board[(i*COLS) + j] == self.board[i*COLS + (j+1)] == self.board[i*COLS + (j+2)]:\n",
    "                    if self.board[(i*COLS) + j] != 0:\n",
    "                        winner = self.board[(i*COLS) + j]\n",
    "\n",
    "        #Win by left->right diagonal\n",
    "        for i in range(0, COLS-2):\n",
    "            for j in range(0,  ROWS-2):\n",
    "                if self.board[(j*COLS) + i] == self.board[((j+1)*COLS) + (i+1)] == self.board[((j+2)*COLS) + (i+2)]:\n",
    "                    if self.board[(j*COLS) + i] != 0:\n",
    "                        winner = self.board[(j*COLS) + i]\n",
    "\n",
    "        #Win by right->left diagonal\n",
    "        for i in range(COLS-1, 1, -1):\n",
    "            for j in range(0,  ROWS-2):\n",
    "                if self.board[(j*COLS) + i] == self.board[((j+1)*COLS) + (i-1)] == self.board[((j+2)*COLS) + (i-2)]:\n",
    "                    if self.board[(j*COLS) + i] != 0:\n",
    "                        winner =self.board[(j*COLS) + i]\n",
    "        \n",
    "        return winner\n",
    "    \n",
    "    def optimalPlay(self, p1: Agent, p2: Agent):\n",
    "        self.board = [0 for _ in range(ROWS*COLS)]\n",
    "        while True:\n",
    "            p1_action = p1.chooseBest(self.board)\n",
    "            self.updateBoard(p1_action, p1.symbol)\n",
    "            winner = self.checkWin()\n",
    "            if winner != \"NA\":\n",
    "                return winner, self.board\n",
    "            else:\n",
    "                p2_action = p2.chooseBest(self.board)\n",
    "                self.updateBoard(p2_action, p2.symbol)\n",
    "                winner = self.checkWin()\n",
    "                if winner != \"NA\":\n",
    "                    return winner, self.board\n",
    "            \n",
    "    def playAsHuman(self, p1: Agent, order: int):\n",
    "        while True:\n",
    "            if(order == 1): #The agent goes first\n",
    "                p1_action = p1.chooseBest(self.board)\n",
    "                self.updateBoard(p1_action, p1.symbol)\n",
    "                winner = self.checkWin()\n",
    "                if winner != \"NA\":\n",
    "                    return winner, self.board\n",
    "                else:\n",
    "                    print(\"Current Board: \", self.board)\n",
    "                    p2_action = int(input(\"enter Position:\"))\n",
    "                    self.updateBoard(p2_action, \"O\")\n",
    "                    winner = self.checkWin()\n",
    "                    if winner != \"NA\":\n",
    "                        return winner, self.board\n",
    "\n",
    "    def play(self, p1: Agent, p2: Agent):\n",
    "        self.board = [0 for _ in range(ROWS*COLS)]\n",
    "        complete = False\n",
    "        while not complete:\n",
    "            action = p1.chooseAction(self.board)\n",
    "            self.updateBoard(action, p1.symbol)\n",
    "            p1.addToHistory(self.board)\n",
    "\n",
    "            winner = self.checkWin()\n",
    "            if winner != \"NA\":\n",
    "                complete = True\n",
    "                if winner == p1.symbol:\n",
    "                    p1.updateStateValue(1)\n",
    "                    p2.updateStateValue(0)\n",
    "                elif winner == p2.symbol:\n",
    "                    p1.updateStateValue(0)\n",
    "                    p2.updateStateValue(1)\n",
    "                else:\n",
    "                    p1.updateStateValue(0.1)\n",
    "                    p2.updateStateValue(0.5)\n",
    "                p1.reset()\n",
    "                p2.reset()\n",
    "                bc = self.board\n",
    "                self.board = [0 for _ in range(ROWS*COLS)]\n",
    "                return winner, bc\n",
    "                \n",
    "            else:\n",
    "                action = p2.chooseAction(self.board)\n",
    "                self.updateBoard(action, p2.symbol)\n",
    "                p2.addToHistory(self.board)\n",
    "                winner = self.checkWin()\n",
    "                if winner != \"NA\":\n",
    "                    complete = True\n",
    "                    if winner == p1.symbol:\n",
    "                        p1.updateStateValue(1)\n",
    "                        p2.updateStateValue(0)\n",
    "                    elif winner == p2.symbol:\n",
    "                        p1.updateStateValue(0)\n",
    "                        p2.updateStateValue(1)\n",
    "                    else:\n",
    "                        p1.updateStateValue(0.1)\n",
    "                        p2.updateStateValue(0.5)\n",
    "                    p1.reset()\n",
    "                    p2.reset()\n",
    "                    bc = self.board\n",
    "                    self.board = [0 for _ in range(ROWS*COLS)]\n",
    "                    return winner, bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePolicy(p1 :Agent, p2: Agent):\n",
    "    with open(\"Policy_player1\", 'wb') as f:\n",
    "        pickle.dump(p1.stateValueTable, f)\n",
    "    \n",
    "    with open(\"Policy_player2\", 'wb') as f:\n",
    "        pickle.dump(p2.stateValueTable, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Agent(\"X\")\n",
    "p2 = Agent(\"O\")\n",
    "bg = env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "Round: 10000\n",
      "Round: 20000\n",
      "Round: 30000\n",
      "Round: 40000\n",
      "Demo: \n"
     ]
    }
   ],
   "source": [
    "def train(p1, p2):\n",
    "    for i in range(50000):\n",
    "        if i% 10000 == 0:\n",
    "            print(\"Round: \" + str(i))\n",
    "        bg.play(p1,p2)\n",
    "    print(\"Demo: \")\n",
    "    bg.optimalPlay(p1,p2)\n",
    "    savePolicy(p1,p2)\n",
    "train(p1,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Board:  [0, 0, 0, 0, 0, 0, 'X', 0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Board:  [0, 'O', 0, 0, 0, 0, 'X', 0, 'X']\n",
      "Current Board:  [0, 'O', 0, 0, 'X', 0, 'X', 'O', 'X']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('X', ['O', 'O', 'X', 0, 'X', 0, 'X', 'O', 'X'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentPlayer1 = Agent(\"X\")\n",
    "agentPlayer1.loadPolicy(\"Policy_player1\")\n",
    "\n",
    "play_env = env()\n",
    "play_env.playAsHuman(agentPlayer1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
